{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of VC2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1LUxk3ImfS6ytF8UkogSw4H3-3s46hKpI",
      "authorship_tag": "ABX9TyOfEAiGZVl6kDPpHkw9no2c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mapledxf/espnet/blob/master/VC2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpy054YGVMQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OS setup\n",
        "!cat /etc/os-release\n",
        "!apt-get install -qq bc tree sox\n",
        "\n",
        "# espnet setup\n",
        "!git clone --depth 5 https://github.com/mapledxf/espnet.git\n",
        "!pip install -q torch==1.1\n",
        "!cd espnet; pip install -q -e .\n",
        "\n",
        "# download pre-compiled warp-ctc and kaldi tools\n",
        "!espnet/utils/download_from_google_drive.sh \\\n",
        "    \"https://drive.google.com/open?id=13Y4tSygc8WtqzvAVGK_vRV9GlV7TRC0w\" espnet/tools tar.gz > /dev/null\n",
        "!cd espnet/tools/warp-ctc/pytorch_binding && \\\n",
        "    pip install -U dist/warpctc_pytorch-0.1.1-cp36-cp36m-linux_x86_64.whl\n",
        "!pip install -U parallel_wavegan\n",
        "# make dummy activate\n",
        "!mkdir -p espnet/tools/venv/bin && touch espnet/tools/venv/bin/activate\n",
        "!echo \"setup done.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IrV7Fp6Fh-j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "1e1c5feb-3c17-4461-bd50-269178835851"
      },
      "source": [
        "!cd espnet/tools; make"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "g++  -Wl,-rpath=/content/espnet/tools/kaldi/tools/openfst-1.6.7/lib  -rdynamic  -Wl,-rpath=/content/espnet/tools/kaldi/src/lib  rnnlm-compute-prob.o   ../rnnlm/libkaldi-rnnlm.so  ../nnet3/libkaldi-nnet3.so  ../cudamatrix/libkaldi-cudamatrix.so  ../decoder/libkaldi-decoder.so  ../lat/libkaldi-lat.so  ../lm/libkaldi-lm.so  ../fstext/libkaldi-fstext.so  ../hmm/libkaldi-hmm.so  ../transform/libkaldi-transform.so  ../gmm/libkaldi-gmm.so  ../tree/libkaldi-tree.so  ../util/libkaldi-util.so  ../matrix/libkaldi-matrix.so  ../base/libkaldi-base.so /content/espnet/tools/kaldi/tools/openfst-1.6.7/lib/libfst.so /usr/lib/x86_64-linux-gnu//libatlas.so.3 /usr/lib/x86_64-linux-gnu//libf77blas.so.3 /usr/lib/x86_64-linux-gnu//libcblas.so.3 /usr/lib/x86_64-linux-gnu//liblapack_atlas.so.3 -Wl,-rpath=/usr/lib/x86_64-linux-gnu -lm -lpthread -ldl  -o rnnlm-compute-prob\n",
            "g++ -std=c++11 -I.. -isystem /content/espnet/tools/kaldi/tools/openfst-1.6.7/include -O1 -Wno-sign-compare -Wall -Wno-sign-compare -Wno-unused-local-typedefs -Wno-deprecated-declarations -Winit-self -DKALDI_DOUBLEPRECISION=0 -DHAVE_EXECINFO_H=1 -DHAVE_CXXABI_H -DHAVE_ATLAS -I/content/espnet/tools/kaldi/tools/ATLAS_headers/include -msse -msse2 -pthread -g  -fPIC   -c -o rnnlm-sentence-probs.o rnnlm-sentence-probs.cc\n",
            "g++  -Wl,-rpath=/content/espnet/tools/kaldi/tools/openfst-1.6.7/lib  -rdynamic  -Wl,-rpath=/content/espnet/tools/kaldi/src/lib  rnnlm-sentence-probs.o   ../rnnlm/libkaldi-rnnlm.so  ../nnet3/libkaldi-nnet3.so  ../cudamatrix/libkaldi-cudamatrix.so  ../decoder/libkaldi-decoder.so  ../lat/libkaldi-lat.so  ../lm/libkaldi-lm.so  ../fstext/libkaldi-fstext.so  ../hmm/libkaldi-hmm.so  ../transform/libkaldi-transform.so  ../gmm/libkaldi-gmm.so  ../tree/libkaldi-tree.so  ../util/libkaldi-util.so  ../matrix/libkaldi-matrix.so  ../base/libkaldi-base.so /content/espnet/tools/kaldi/tools/openfst-1.6.7/lib/libfst.so /usr/lib/x86_64-linux-gnu//libatlas.so.3 /usr/lib/x86_64-linux-gnu//libf77blas.so.3 /usr/lib/x86_64-linux-gnu//libcblas.so.3 /usr/lib/x86_64-linux-gnu//liblapack_atlas.so.3 -Wl,-rpath=/usr/lib/x86_64-linux-gnu -lm -lpthread -ldl  -o rnnlm-sentence-probs\n",
            "make[2]: Leaving directory '/content/espnet/tools/kaldi/src/rnnlmbin'\n",
            "make -C cudadecoderbin\n",
            "make[2]: Entering directory '/content/espnet/tools/kaldi/src/cudadecoderbin'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/content/espnet/tools/kaldi/src/cudadecoderbin'\n",
            "make -C matrix test\n",
            "make[2]: Entering directory '/content/espnet/tools/kaldi/src/matrix'\n",
            "g++ -std=c++11 -I.. -isystem /content/espnet/tools/kaldi/tools/openfst-1.6.7/include -O1  -Wall -Wno-sign-compare -Wno-unused-local-typedefs -Wno-deprecated-declarations -Winit-self -DKALDI_DOUBLEPRECISION=0 -DHAVE_EXECINFO_H=1 -DHAVE_CXXABI_H -DHAVE_ATLAS -I/content/espnet/tools/kaldi/tools/ATLAS_headers/include -msse -msse2 -pthread -g  -fPIC   -c -o matrix-lib-test.o matrix-lib-test.cc\n",
            "g++  -Wl,-rpath=/content/espnet/tools/kaldi/tools/openfst-1.6.7/lib  -rdynamic -Wl,-rpath=/content/espnet/tools/kaldi/src/lib  matrix-lib-test.o libkaldi-matrix.so   ../base/libkaldi-base.so /content/espnet/tools/kaldi/tools/openfst-1.6.7/lib/libfst.so /usr/lib/x86_64-linux-gnu//libatlas.so.3 /usr/lib/x86_64-linux-gnu//libf77blas.so.3 /usr/lib/x86_64-linux-gnu//libcblas.so.3 /usr/lib/x86_64-linux-gnu//liblapack_atlas.so.3 -Wl,-rpath=/usr/lib/x86_64-linux-gnu -lm -lpthread -ldl -o matrix-lib-test\n",
            "g++ -std=c++11 -I.. -isystem /content/espnet/tools/kaldi/tools/openfst-1.6.7/include -O1  -Wall -Wno-sign-compare -Wno-unused-local-typedefs -Wno-deprecated-declarations -Winit-self -DKALDI_DOUBLEPRECISION=0 -DHAVE_EXECINFO_H=1 -DHAVE_CXXABI_H -DHAVE_ATLAS -I/content/espnet/tools/kaldi/tools/ATLAS_headers/include -msse -msse2 -pthread -g  -fPIC   -c -o sparse-matrix-test.o sparse-matrix-test.cc\n",
            "g++  -Wl,-rpath=/content/espnet/tools/kaldi/tools/openfst-1.6.7/lib  -rdynamic -Wl,-rpath=/content/espnet/tools/kaldi/src/lib  sparse-matrix-test.o libkaldi-matrix.so   ../base/libkaldi-base.so /content/espnet/tools/kaldi/tools/openfst-1.6.7/lib/libfst.so /usr/lib/x86_64-linux-gnu//libatlas.so.3 /usr/lib/x86_64-linux-gnu//libf77blas.so.3 /usr/lib/x86_64-linux-gnu//libcblas.so.3 /usr/lib/x86_64-linux-gnu//liblapack_atlas.so.3 -Wl,-rpath=/usr/lib/x86_64-linux-gnu -lm -lpthread -ldl -o sparse-matrix-test\n",
            "Running matrix-lib-test ... 2s... SUCCESS matrix-lib-test\n",
            "Running sparse-matrix-test ... 0s... SUCCESS sparse-matrix-test\n",
            "make[2]: Leaving directory '/content/espnet/tools/kaldi/src/matrix'\n",
            "echo Done\n",
            "Done\n",
            "make[1]: Leaving directory '/content/espnet/tools/kaldi/src'\n",
            "touch kaldi.done\n",
            "test -f miniconda.sh || wget --tries=3 https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh\n",
            "--2020-03-19 06:29:22--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85055499 (81M) [application/x-sh]\n",
            "Saving to: ‘miniconda.sh’\n",
            "\n",
            "miniconda.sh        100%[===================>]  81.12M   257MB/s    in 0.3s    \n",
            "\n",
            "2020-03-19 06:29:22 (257 MB/s) - ‘miniconda.sh’ saved [85055499/85055499]\n",
            "\n",
            ". venv/bin/activate && conda install -y pytorch=1.0.1 cudatoolkit=10.0 -c pytorch\n",
            "/bin/sh: 1: conda: not found\n",
            "Makefile:76: recipe for target 'espnet.done' failed\n",
            "make: *** [espnet.done] Error 127\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LILqYB7I8EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p /content/espnet/egs/vcc20/vc1_task1/downloads\n",
        "!tar xzvf /content/drive/My\\ Drive/vcc.tar -C /content/espnet/egs/vcc20/vc1_task1/downloads/\n",
        "!mv /content/espnet/egs/vcc20/vc1_task1/downloads/vcc2020_training /content/espnet/egs/vcc20/vc1_task1/downloads/official_v1.0_training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9St-I92WcK_",
        "colab_type": "code",
        "outputId": "beda0ee2-35b1-4031-beb1-4e5cbb33c609",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/espnet/egs/vcc20/vc1_task1\")\n",
        "!./run.sh --pretrained_model_name tts1 --out_dir /output --dataset /output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stage -1: Data and Pretrained model download\n",
            "Please download the dataset following the README.\n",
            "Downloading pretrained TTS model...\n",
            "--2020-03-19 06:37:34--  https://drive.google.com/uc?export=download&id=1Xj73mDPuuPH8GsyNO8GnOC3mn0_OK4g3\n",
            "Resolving drive.google.com (drive.google.com)... 64.233.167.113, 64.233.167.138, 64.233.167.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|64.233.167.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: 'downloads/tts1/or7jxb..tar.gz'\n",
            "\n",
            "\r          downloads     [<=>                 ]       0  --.-KB/s               \rdownloads/tts1/or7j     [ <=>                ]   3.22K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-03-19 06:37:34 (29.8 MB/s) - 'downloads/tts1/or7jxb..tar.gz' saved [3301]\n",
            "\n",
            "\n",
            "gzip: stdin: not in gzip format\n",
            "tar: Child returned status 1\n",
            "tar: Error is not recoverable: exiting now\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3301    0  3301    0     0  16181      0 --:--:-- --:--:-- --:--:-- 16181\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   408    0   408    0     0   1829      0 --:--:-- --:--:-- --:--:--  1821\r100   408    0   408    0     0   1829      0 --:--:-- --:--:-- --:--:--  1821\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100  107M    0  107M    0     0  23.3M      0 --:--:--  0:00:04 --:--:-- 37.1M\n",
            "conf/train_pytorch_transformer+spkemb.yaml\n",
            "conf/decode.yaml\n",
            "data/train_clean_460/cmvn.ark\n",
            "exp/train_clean_460_pytorch_train_pytorch_transformer+spkemb.v5/results/model.last1.avg.best\n",
            "exp/train_clean_460_pytorch_train_pytorch_transformer+spkemb.v5/results/model.json\n",
            "data/lang_1char/train_clean_460_units.txt\n",
            "Sucessfully downloaded zip file from https://drive.google.com/open?id=1Xj73mDPuuPH8GsyNO8GnOC3mn0_OK4g3\n",
            "Successfully finished donwload of pretrained model.\n",
            "Pretrained TTS model exists: tts1\n",
            "Downloading pretrained PWG model...\n",
            "--2020-03-19 06:37:41--  https://drive.google.com/uc?export=download&id=11KKux-du6fvsMMB4jNk9YH23YUJjRcDV\n",
            "Resolving drive.google.com (drive.google.com)... 64.233.184.113, 64.233.184.138, 64.233.184.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|64.233.184.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0c-5c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ofakm25udapnugfskmai08k4cobu1pur/1584599850000/17416569198586637370/*/11KKux-du6fvsMMB4jNk9YH23YUJjRcDV?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-03-19 06:37:44--  https://doc-0c-5c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ofakm25udapnugfskmai08k4cobu1pur/1584599850000/17416569198586637370/*/11KKux-du6fvsMMB4jNk9YH23YUJjRcDV?e=download\n",
            "Resolving doc-0c-5c-docs.googleusercontent.com (doc-0c-5c-docs.googleusercontent.com)... 64.233.166.132, 2a00:1450:400c:c09::84\n",
            "Connecting to doc-0c-5c-docs.googleusercontent.com (doc-0c-5c-docs.googleusercontent.com)|64.233.166.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: 'downloads/pwg_task1/a9h7z8..tar.gz'\n",
            "\n",
            "downloads/pwg_task1     [  <=>               ]  14.87M  20.4MB/s    in 0.7s    \n",
            "\n",
            "2020-03-19 06:37:45 (20.4 MB/s) - 'downloads/pwg_task1/a9h7z8..tar.gz' saved [15587750]\n",
            "\n",
            "checkpoint-400000steps.pkl\n",
            "config.yml\n",
            "stats.h5\n",
            "Sucessfully downloaded zip file from https://drive.google.com/open?id=11KKux-du6fvsMMB4jNk9YH23YUJjRcDV\n",
            "Successfully finished donwload of pretrained model.\n",
            "PWG model exists: downloads/pwg_task1\n",
            "stage 0: Data preparation\n",
            "finished making wav.scp, utt2spk, spk2utt.\n",
            "finished making text.\n",
            "utils/data/get_utt2dur.sh: segments file does not exist so getting durations from wave files\n",
            "utils/data/get_utt2dur.sh: could not get utterance lengths from sphere-file headers, using wav-to-duration\n",
            "utils/data/get_utt2dur.sh: computed data/TEF1/utt2dur\n",
            "fix_data_dir.sh: kept all 70 utterances.\n",
            "fix_data_dir.sh: old files are kept in data/TEF1/.backup\n",
            "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
            "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
            "   for more information.\n",
            "utils/validate_data_dir.sh: Successfully validated data-directory data/TEF1\n",
            "stage 1: Feature Generation\n",
            "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
            "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
            "   for more information.\n",
            "utils/validate_data_dir.sh: Successfully validated data-directory data/TEF1\n",
            "Successfully trimed silence part.\n",
            "/content/espnet/egs/vcc20/vc1_task1/../../../utils/make_fbank.sh --cmd run.pl --nj 10 --fs 24000 --fmax 7600 --fmin 80 --n_fft 1024 --n_shift 256 --win_length  --n_mels 80 data/TEF1 exp/make_fbank/TEF1 fbank\n",
            "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
            "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
            "   for more information.\n",
            "utils/validate_data_dir.sh: Successfully validated data-directory data/TEF1\n",
            "/content/espnet/egs/vcc20/vc1_task1/../../../utils/make_fbank.sh [info]: segments file exists: using that.\n",
            "Succeeded creating filterbank features for TEF1\n",
            "utils/subset_data_dir.sh: reducing #utt from 70 to 60\n",
            "utils/subset_data_dir.sh: reducing #utt from 70 to 10\n",
            "/content/espnet/egs/vcc20/vc1_task1/../../../utils/dump.sh --cmd run.pl --nj 10 --do_delta false data/TEF1_train/feats.scp downloads/tts1/data/train_clean_460/cmvn.ark exp/dump_feats/TEF1_train dump/TEF1_train\n",
            "/content/espnet/egs/vcc20/vc1_task1/../../../utils/dump.sh --cmd run.pl --nj 10 --do_delta false data/TEF1_dev/feats.scp downloads/tts1/data/train_clean_460/cmvn.ark exp/dump_feats/TEF1_dev dump/TEF1_dev\n",
            "stage 2: Dictionary and Json Data Preparation\n",
            "dictionary: downloads/tts1/data/lang_1char/train_clean_460_units.txt\n",
            "/content/espnet/egs/vcc20/vc1_task1/../../../utils/data2json.sh --feat dump/TEF1_train/feats.scp --trans_type char data/TEF1_train downloads/tts1/data/lang_1char/train_clean_460_units.txt\n",
            "/content/espnet/egs/vcc20/vc1_task1/../../../utils/feat_to_shape.sh --cmd run.pl --nj 1 --filetype  --preprocess-conf  --verbose 0 dump/TEF1_train/feats.scp data/TEF1_train/tmp-XbqDJ/input_1/shape.scp\n",
            "/content/espnet/egs/vcc20/vc1_task1/../../../utils/data2json.sh --feat dump/TEF1_dev/feats.scp --trans_type char data/TEF1_dev downloads/tts1/data/lang_1char/train_clean_460_units.txt\n",
            "/content/espnet/egs/vcc20/vc1_task1/../../../utils/feat_to_shape.sh --cmd run.pl --nj 1 --filetype  --preprocess-conf  --verbose 0 dump/TEF1_dev/feats.scp data/TEF1_dev/tmp-XFFSh/input_1/shape.scp\n",
            "stage 3: x-vector extraction\n",
            "utils/copy_data_dir.sh: copied data from data/TEF1_train to data/TEF1_train_mfcc_16k\n",
            "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
            "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
            "   for more information.\n",
            "utils/validate_data_dir.sh: Successfully validated data-directory data/TEF1_train_mfcc_16k\n",
            "utils/data/resample_data_dir.sh: feats.scp already exists. Moving it to data/TEF1_train_mfcc_16k/.backup\n",
            "steps/make_mfcc.sh --write-utt2num-frames true --mfcc-config conf/mfcc.conf --nj 1 --cmd run.pl data/TEF1_train_mfcc_16k exp/make_mfcc_16k mfcc\n",
            "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
            "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
            "   for more information.\n",
            "utils/validate_data_dir.sh: Successfully validated data-directory data/TEF1_train_mfcc_16k\n",
            "steps/make_mfcc.sh [info]: segments file exists: using that.\n",
            "steps/make_mfcc.sh: Succeeded creating MFCC features for TEF1_train_mfcc_16k\n",
            "fix_data_dir.sh: kept all 60 utterances.\n",
            "fix_data_dir.sh: old files are kept in data/TEF1_train_mfcc_16k/.backup\n",
            "sid/compute_vad_decision.sh --nj 1 --cmd run.pl data/TEF1_train_mfcc_16k exp/make_vad mfcc\n",
            "Created VAD output for TEF1_train_mfcc_16k\n",
            "fix_data_dir.sh: kept all 60 utterances.\n",
            "fix_data_dir.sh: old files are kept in data/TEF1_train_mfcc_16k/.backup\n",
            "utils/copy_data_dir.sh: copied data from data/TEF1_dev to data/TEF1_dev_mfcc_16k\n",
            "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
            "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
            "   for more information.\n",
            "utils/validate_data_dir.sh: Successfully validated data-directory data/TEF1_dev_mfcc_16k\n",
            "utils/data/resample_data_dir.sh: feats.scp already exists. Moving it to data/TEF1_dev_mfcc_16k/.backup\n",
            "steps/make_mfcc.sh --write-utt2num-frames true --mfcc-config conf/mfcc.conf --nj 1 --cmd run.pl data/TEF1_dev_mfcc_16k exp/make_mfcc_16k mfcc\n",
            "utils/validate_data_dir.sh: WARNING: you have only one speaker.  This probably a bad idea.\n",
            "   Search for the word 'bold' in http://kaldi-asr.org/doc/data_prep.html\n",
            "   for more information.\n",
            "utils/validate_data_dir.sh: Successfully validated data-directory data/TEF1_dev_mfcc_16k\n",
            "steps/make_mfcc.sh [info]: segments file exists: using that.\n",
            "steps/make_mfcc.sh: Succeeded creating MFCC features for TEF1_dev_mfcc_16k\n",
            "fix_data_dir.sh: kept all 10 utterances.\n",
            "fix_data_dir.sh: old files are kept in data/TEF1_dev_mfcc_16k/.backup\n",
            "sid/compute_vad_decision.sh --nj 1 --cmd run.pl data/TEF1_dev_mfcc_16k exp/make_vad mfcc\n",
            "Created VAD output for TEF1_dev_mfcc_16k\n",
            "fix_data_dir.sh: kept all 10 utterances.\n",
            "fix_data_dir.sh: old files are kept in data/TEF1_dev_mfcc_16k/.backup\n",
            "X-vector model does not exist. Download pre-trained model.\n",
            "--2020-03-19 06:39:21--  http://kaldi-asr.org/models/8/0008_sitw_v2_1a.tar.gz\n",
            "Resolving kaldi-asr.org (kaldi-asr.org)... 46.101.158.64\n",
            "Connecting to kaldi-asr.org (kaldi-asr.org)|46.101.158.64|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30770196 (29M) [application/x-gzip]\n",
            "Saving to: '0008_sitw_v2_1a.tar.gz'\n",
            "\n",
            "0008_sitw_v2_1a.tar 100%[===================>]  29.34M  8.15MB/s    in 3.6s    \n",
            "\n",
            "2020-03-19 06:39:25 (8.15 MB/s) - '0008_sitw_v2_1a.tar.gz' saved [30770196/30770196]\n",
            "\n",
            "0008_sitw_v2_1a/\n",
            "0008_sitw_v2_1a/run.sh\n",
            "0008_sitw_v2_1a/exp/\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/final.raw\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/max_chunk_size\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/min_chunk_size\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/extract.config\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/nnet.config\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/srand\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/xvectors_train_combined_200k/\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/xvectors_train_combined_200k/plda\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/xvectors_train_combined_200k/mean.vec\n",
            "0008_sitw_v2_1a/exp/xvector_nnet_1a/xvectors_train_combined_200k/transform.mat\n",
            "0008_sitw_v2_1a/-/\n",
            "0008_sitw_v2_1a/local/\n",
            "0008_sitw_v2_1a/local/nnet3/\n",
            "0008_sitw_v2_1a/local/nnet3/xvector/\n",
            "0008_sitw_v2_1a/local/nnet3/xvector/tuning/\n",
            "0008_sitw_v2_1a/local/nnet3/xvector/tuning/run_xvector_1a.sh\n",
            "0008_sitw_v2_1a/README.txt\n",
            "sid/nnet3/xvector/extract_xvectors.sh --cmd run.pl --mem 4G --nj 1 exp/xvector_nnet_1a data/TEF1_train_mfcc_16k exp/xvector_nnet_1a/xvectors_TEF1_train\n",
            "sid/nnet3/xvector/extract_xvectors.sh: using exp/xvector_nnet_1a/extract.config to extract xvectors\n",
            "sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/TEF1_train_mfcc_16k\n",
            "sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet\n",
            "sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs\n",
            "sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker\n",
            "sid/nnet3/xvector/extract_xvectors.sh --cmd run.pl --mem 4G --nj 1 exp/xvector_nnet_1a data/TEF1_dev_mfcc_16k exp/xvector_nnet_1a/xvectors_TEF1_dev\n",
            "sid/nnet3/xvector/extract_xvectors.sh: using exp/xvector_nnet_1a/extract.config to extract xvectors\n",
            "sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors for data/TEF1_dev_mfcc_16k\n",
            "sid/nnet3/xvector/extract_xvectors.sh: extracting xvectors from nnet\n",
            "sid/nnet3/xvector/extract_xvectors.sh: combining xvectors across jobs\n",
            "sid/nnet3/xvector/extract_xvectors.sh: computing mean of xvectors for each speaker\n",
            "json updated. original json is kept in dump/TEF1_train/.backup.\n",
            "json updated. original json is kept in dump/TEF1_dev/.backup.\n",
            "stage 4: Text-to-speech model fine-tuning\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}